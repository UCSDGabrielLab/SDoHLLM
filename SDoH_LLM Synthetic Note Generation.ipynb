{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqxPqWzo3xi7"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "!pip install transformers\n",
        "!pip install simpletransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2TY1qEt9BYZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrblBja-38F-"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "import openai\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import random\n",
        "import pandas as pd\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_yU1KZGcGGN"
      },
      "outputs": [],
      "source": [
        "seed_value = 42\n",
        "random.seed(seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNxoOduwNxkW"
      },
      "source": [
        "### OpenAI data generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JggV03xq4V_q"
      },
      "outputs": [],
      "source": [
        "openai.organization = os.environ.get('organisation')\n",
        "openai.api_key = os.environ.get('Key')\n",
        "# openai.Model.list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cylc9o0DBGCB"
      },
      "outputs": [],
      "source": [
        "command_homelessness = \"\"\"I'm creating a dataset to train an NLP model which can identify 'Social determinants of Health'\n",
        "when given a medical report of a patient. The determinant which I want to focus on is 'Homelessness'. Give me 100\n",
        "examples which each at least have 1 to 2 sentences related to the determinant 'Homelessness'.   Limit the use of the\n",
        "phrase 'Homelessness' when possible. Just give the text, don't include the patient name and other information.\n",
        "Each example should start with keyword  'Determinant Example'.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXLfGdVODHZG"
      },
      "outputs": [],
      "source": [
        "command_food_insecurity = \"\"\"I'm creating a dataset to train an NLP model which can identify 'Social determinants of Health'\n",
        "when given a medical report of a patient. The determinant which I want to focus on is 'Food Insecurity'. Give me 100\n",
        "examples which each at least have 1 to 2 sentences related to the determinant 'Food Insecurity'.   Limit the use of the\n",
        "phrase 'Food Insecurity' when possible. Just give the text, don't include the patient name and other information.\n",
        "Each example should start with keyword  'Determinant Example'.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "command_domestic_violence = \"\"\"I'm creating a dataset to train an NLP model which can identify 'Social determinants of Health'\n",
        "when given a medical report of a patient. The determinant which I want to focus on is 'Domestic Violence'. Give me 100\n",
        "examples which each at least have 1 to 2 sentences related to the determinant 'Domestic Violence'.   Limit the use of the\n",
        "phrase 'Domestic Violence' when possible. Just give the text, don't include the patient name and other information.\n",
        "Each example should start with keyword  'Determinant Example'.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BiBWvAd4nQ7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "libkCqeYTHBw"
      },
      "outputs": [],
      "source": [
        "command_not_food_insecurty = \"\"\"I'm creating a dataset to train an NLP model which can identify 'Social determinants of\n",
        "Health' when given a medical report of a patient. The determinant which I want to focus on is 'Food Insecurity'. Give me\n",
        "100 examples which each at least have 1 to 2 sentences related to the patient not having issues with 'Food Insecurity'.\n",
        "Limit the use of the phrase 'Food Insecurity' when possible. Just give the text, don't include the patient name and\n",
        "other information. Each example should start with keyword  'Determinant Example'.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZGKvR_w3u0N"
      },
      "outputs": [],
      "source": [
        "command_not_homelessness = \"\"\"I'm creating a dataset to train an NLP model which can identify 'Social determinants of\n",
        "Health' when given a medical report of a patient. The determinant which I want to focus on is 'Homelessness'. Give me\n",
        "100 examples which each at least have 1 to 2 sentences related to the patient not having issues with 'Homelessness'.\n",
        "Limit the use of the phrase 'Homelessness' when possible. Just give the text, don't include the patient name and\n",
        "other information. Each example should start with keyword  'Determinant Example'.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "command_not_domestic_violence = \"\"\"I'm creating a dataset to train an NLP model which can identify 'Social determinants of\n",
        "Health' when given a medical report of a patient. The determinant which I want to focus on is 'Domestic Violence'. Give me\n",
        "100 examples which each at least have 1 to 2 sentences related to the patient not having issues with 'Domestic Violence'.\n",
        "Limit the use of the phrase 'Domestic Violence' when possible. Just give the text, don't include the patient name and\n",
        "other information. Each example should start with keyword  'Determinant Example'.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0eLTxZl4G_v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX6BZ8f2VLpE"
      },
      "outputs": [],
      "source": [
        "def generate_data(command, keyword_determinant):\n",
        "  for i in range(1):\n",
        "    message = [{\"role\": \"system\", \"content\": command}]\n",
        "    response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages = message)\n",
        "    file_name = keyword_determinant + str(i) + '.txt'\n",
        "    with open(file_name, \"w\") as file:\n",
        "      file.write(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZQbbHfaWF2F"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "generate_data(command_homelessness, 'Homelessness')\n",
        "generate_data(command_food_insecurity, 'Food Insecurity')\n",
        "generate_data(command_not_food_insecurty, 'Food Abundance')\n",
        "generate_data(command_not_homelessness, 'Housing Avaialble')\n",
        "generate_data(command_domestic_violence, 'Domestic Violence')\n",
        "generate_data(command_not_domestic_violence, 'NOT Domestic Violence')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e18_1ZKLN0ob"
      },
      "source": [
        "### Data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjPeBFDL5k8-"
      },
      "outputs": [],
      "source": [
        "def read_data(file_name):\n",
        "\n",
        "  tree = ET.parse(file_name)\n",
        "  root = tree.getroot()\n",
        "  file_content = root[0].text\n",
        "  return file_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIdhe8-MN7uq"
      },
      "outputs": [],
      "source": [
        "def pre_process_data(file_content):\n",
        "\n",
        "  clean_data = file_content.replace('\\n\\n', '.')\n",
        "  clean_data = clean_data.replace('\\n', '')\n",
        "  clean_data = clean_data.replace(\"\\'\", \"\")\n",
        "  clean_data = clean_data.replace(\"\\t\", \" \")\n",
        "  split_string = clean_data.split('.')\n",
        "  cleaned_parts = [part.strip() for part in split_string if part.strip()]\n",
        "  modified_string = '.'.join(cleaned_parts)\n",
        "  return modified_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0sav68TOmyc"
      },
      "outputs": [],
      "source": [
        "data = {}\n",
        "combined_data = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BugTiigFOurU"
      },
      "outputs": [],
      "source": [
        "%cd /i2b/training-PHI-Gold-Set1\n",
        "\n",
        "file_list = os.listdir()\n",
        "for file_name in file_list:\n",
        "  file_content = read_data(file_name)\n",
        "  cleaned_data = pre_process_data(file_content)\n",
        "\n",
        "  key = int(file_name.split('-')[0])\n",
        "  if key in data:\n",
        "    value = data[key]\n",
        "    value.append(cleaned_data)\n",
        "    data[key] = value\n",
        "  else:\n",
        "    data[key] = [cleaned_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afBNQaD0Ov1H"
      },
      "outputs": [],
      "source": [
        "%cd /i2b/training-PHI-Gold-Set2\n",
        "\n",
        "file_list = os.listdir()\n",
        "for file_name in file_list:\n",
        "  file_content = read_data(file_name)\n",
        "  cleaned_data = pre_process_data(file_content)\n",
        "\n",
        "  key = int(file_name.split('-')[0])\n",
        "  if key in data:\n",
        "    value = data[key]\n",
        "    value.append(cleaned_data)\n",
        "    data[key] = value\n",
        "  else:\n",
        "    data[key] = [cleaned_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqD1W2rMPgxB"
      },
      "outputs": [],
      "source": [
        "# Medical Notes\n",
        "\n",
        "medical_notes = list()\n",
        "count = 0\n",
        "\n",
        "for k in data:\n",
        "  for i in range(len(data[k])):\n",
        "    medical_notes.append(data[k][i])\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dG2OqMCPevo"
      },
      "outputs": [],
      "source": [
        "def extract_determinant_notes(keyword):\n",
        "\n",
        "  split_content = list()\n",
        "\n",
        "  file_list = os.listdir()\n",
        "  for file_name in file_list:\n",
        "    if keyword in file_name:\n",
        "      with open(file_name, 'r') as file:\n",
        "        content = file.read()\n",
        "        if file_name == 'Food Abundance0.txt' or file_name == 'Food Insecurity updated0.txt' or file_name == 'Domestic Violence2.txt' or file_name == 'Violence Absent.txt':\n",
        "          split_content.append(content.split('\\n'))\n",
        "        else:\n",
        "          split_content.append(content.split('\\n\\n'))\n",
        "\n",
        "  determinant = list()\n",
        "\n",
        "\n",
        "  for i in range(len(split_content)):\n",
        "    for j in range(len(split_content[i])):\n",
        "      if keyword == 'Food Abundance' or keyword == 'Violence Absent':\n",
        "        determinant.append(split_content[i][j][21:])\n",
        "      else:\n",
        "        determinant.append(split_content[i][j][22 + len(str(j+1)): ])\n",
        "\n",
        "  return determinant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6YGW0F1Pz3Y"
      },
      "outputs": [],
      "source": [
        "%cd /i2b/Training Data\n",
        "\n",
        "# Determinants\n",
        "\n",
        "food_insecurity_determinant = extract_determinant_notes('Food Insecurity')\n",
        "homeless_determinant = extract_determinant_notes('Homelessnes')\n",
        "not_food_insecurity_determinant = extract_determinant_notes('Food Abundance')\n",
        "not_homeless_determinant = extract_determinant_notes('Housing Avaialble')\n",
        "domestic_violence_determinant = extract_determinant_notes('Domestic Violence')\n",
        "not_domestic_violence_determinant = extract_determinant_notes('Violence Absent')\n",
        "\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_not_food_insecurity_determinant = list()\n",
        "ind = list()\n",
        "for i in range(len(not_food_insecurity_determinant)):\n",
        "  if 'food insecurity' in not_food_insecurity_determinant[i].lower():\n",
        "    new_not_food_insecurity_determinant.append(not_food_insecurity_determinant[i])\n",
        "    ind.append(i)\n",
        "\n",
        "for i in range(len(not_food_insecurity_determinant)):\n",
        "  if i not in ind:\n",
        "    new_not_food_insecurity_determinant.append(not_food_insecurity_determinant[i])\n",
        "\n",
        "not_homeless_determinant = new_not_food_insecurity_determinant"
      ],
      "metadata": {
        "id": "2njmfL1ep9XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eMB6Mi1-kaI"
      },
      "outputs": [],
      "source": [
        "new_not_homeless_determinant = list()\n",
        "ind = list()\n",
        "for i in range(len(not_homeless_determinant)):\n",
        "  if 'homelessness' in not_homeless_determinant[i].lower():\n",
        "    new_not_homeless_determinant.append(not_homeless_determinant[i])\n",
        "    ind.append(i)\n",
        "\n",
        "for i in range(len(not_homeless_determinant)):\n",
        "  if i not in ind:\n",
        "    new_not_homeless_determinant.append(not_homeless_determinant[i])\n",
        "\n",
        "not_homeless_determinant = new_not_homeless_determinant"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_not_domestic_violence_determinant = list()\n",
        "ind = list()\n",
        "for i in range(len(not_domestic_violence_determinant)):\n",
        "  if 'violence' in not_domestic_violence_determinant[i].lower():\n",
        "    new_not_domestic_violence_determinant.append(not_domestic_violence_determinant[i])\n",
        "    ind.append(i)\n",
        "\n",
        "for i in range(len(not_domestic_violence_determinant)):\n",
        "  if i not in ind:\n",
        "    new_not_domestic_violence_determinant.append(not_domestic_violence_determinant[i])\n",
        "\n",
        "not_domestic_violence_determinant = new_not_domestic_violence_determinant"
      ],
      "metadata": {
        "id": "dbSAPJ46Ns1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5aKiz9n-0YQ"
      },
      "outputs": [],
      "source": [
        "not_homeless_determinant = not_homeless_determinant[:40]\n",
        "not_food_insecurity_determinant = not_food_insecurity_determinant[:40]\n",
        "not_domestic_violence_determinant = not_domestic_violence_determinant[:40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J2ERqRfQXL6"
      },
      "outputs": [],
      "source": [
        "index_list = list()\n",
        "for i in range(len(homeless_determinant)):\n",
        "  index_list.append(len(homeless_determinant[i].split(' ')))\n",
        "\n",
        "plt.hist(index_list, bins=10, color='blue', edgecolor='black')\n",
        "plt.xlabel('Tokenised length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram - Homelessness')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDHO-mdrRI7q"
      },
      "outputs": [],
      "source": [
        "index_list = list()\n",
        "for i in range(len(food_insecurity_determinant)):\n",
        "  index_list.append(len(food_insecurity_determinant[i].split(' ')))\n",
        "\n",
        "plt.hist(index_list, bins=10, color='blue', edgecolor='black')\n",
        "plt.xlabel('Tokenised length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram - Food Insecurity')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65lMfB4_gi_n"
      },
      "outputs": [],
      "source": [
        "index_list = list()\n",
        "for i in range(len(not_food_insecurity_determinant)):\n",
        "  index_list.append(len(not_food_insecurity_determinant[i].split(' ')))\n",
        "\n",
        "plt.hist(index_list, bins=10, color='blue', edgecolor='black')\n",
        "plt.xlabel('Tokenised length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram - Food Insecurity')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiO8EXNk_QnQ"
      },
      "outputs": [],
      "source": [
        "index_list = list()\n",
        "for i in range(len(not_homeless_determinant)):\n",
        "  index_list.append(len(not_homeless_determinant[i].split(' ')))\n",
        "\n",
        "plt.hist(index_list, bins=10, color='blue', edgecolor='black')\n",
        "plt.xlabel('Tokenised length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram - Food Insecurity')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72Elb6FiRLvD"
      },
      "outputs": [],
      "source": [
        "# Lets take default length of determinant text to be inserted as 27.5 tokens words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVxX1BFlb4k0"
      },
      "outputs": [],
      "source": [
        "seed_value = 42\n",
        "random.seed(seed_value)\n",
        "\n",
        "random.shuffle(medical_notes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OW-o4MzkjpEg"
      },
      "outputs": [],
      "source": [
        "def medical_notes_and_combine_determinant(determinant, not_determinant, medical_notes):\n",
        "\n",
        "  combined_medical_notes = list()\n",
        "\n",
        "  for z in range(len(determinant)):\n",
        "    split_data = medical_notes[z].split('.')\n",
        "    front_count = 0\n",
        "    back_count = 0\n",
        "    final_data = list()\n",
        "    for i in range(len(split_data)):\n",
        "      front_count += len(split_data[i].split(' '))\n",
        "      if front_count <= 242:\n",
        "        continue\n",
        "      else:\n",
        "        final_data += split_data[:i+1]\n",
        "        break\n",
        "\n",
        "    final_data.append(determinant[z][:-1])\n",
        "\n",
        "    for i in range(len(split_data)-1, -1, -1):\n",
        "      back_count += len(split_data[i].split(' '))\n",
        "      if back_count <= 242:\n",
        "        continue\n",
        "      else:\n",
        "        final_data += split_data[i:]\n",
        "        break\n",
        "\n",
        "    final_data = '.'.join(final_data)\n",
        "    combined_medical_notes.append(final_data)\n",
        "\n",
        "# Not Determinant\n",
        "  for z in range(len(not_determinant)):\n",
        "    split_data = medical_notes[len(determinant) + z].split('.')\n",
        "    front_count = 0\n",
        "    back_count = 0\n",
        "    final_data = list()\n",
        "    for i in range(len(split_data)):\n",
        "      front_count += len(split_data[i].split(' '))\n",
        "      if front_count <= 242:\n",
        "        continue\n",
        "      else:\n",
        "        final_data += split_data[:i+1]\n",
        "        break\n",
        "\n",
        "    final_data.append(not_determinant[z][:-1])\n",
        "\n",
        "    for i in range(len(split_data)-1, -1, -1):\n",
        "      back_count += len(split_data[i].split(' '))\n",
        "      if back_count <= 242:\n",
        "        continue\n",
        "      else:\n",
        "        final_data += split_data[i:]\n",
        "        break\n",
        "\n",
        "    final_data = '.'.join(final_data)\n",
        "    combined_medical_notes.append(final_data)\n",
        "\n",
        "  return combined_medical_notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q26EA1B2jwIZ"
      },
      "outputs": [],
      "source": [
        "combined_medical_notes_food_insecurity = medical_notes_and_combine_determinant(food_insecurity_determinant, not_food_insecurity_determinant, medical_notes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Sch3TnP_kl6"
      },
      "outputs": [],
      "source": [
        "combined_medical_notes_homelessness = medical_notes_and_combine_determinant(homeless_determinant, not_homeless_determinant, medical_notes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_medical_notes_domestic_violence = medical_notes_and_combine_determinant(domestic_violence_determinant, not_domestic_violence_determinant, medical_notes)"
      ],
      "metadata": {
        "id": "fXgXtzIAOldq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZqMk1uYqsSo"
      },
      "outputs": [],
      "source": [
        "def get_x_and_y(combined_notes, medical_notes, count_determinant, count_no_determinant):\n",
        "  X = list()\n",
        "  y = list()\n",
        "\n",
        "  for i in range(count_determinant):\n",
        "    X.append(combined_notes[i])\n",
        "    y.append(1)\n",
        "\n",
        "  for i in range(count_determinant, count_determinant + count_no_determinant):\n",
        "    X.append(combined_notes[i])\n",
        "    y.append(2)\n",
        "\n",
        "  for i in range(count_determinant + count_no_determinant, len(medical_notes)):\n",
        "    X.append(medical_notes[i])\n",
        "    y.append(0)\n",
        "\n",
        "  return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KSAo0WicvoC"
      },
      "outputs": [],
      "source": [
        "X_fi, y_fi = get_x_and_y(combined_medical_notes_food_insecurity, medical_notes, len(food_insecurity_determinant), len(not_food_insecurity_determinant))\n",
        "X_h, y_h = get_x_and_y(combined_medical_notes_homelessness, medical_notes, len(homeless_determinant), len(not_homeless_determinant))\n",
        "X_dv, y_dv = get_x_and_y(combined_medical_notes_domestic_violence, medical_notes, len(domestic_violence_determinant), len(not_domestic_violence_determinant))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Pb0k3qWACL7"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "element_count = Counter(y_dv)\n",
        "for element, count in element_count.items():\n",
        "    print(f\"Element {element} appears {count} times\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUEvucMfo54S"
      },
      "outputs": [],
      "source": [
        "train_X_fi, test_x_fi, train_y_fi, test_y_fi = train_test_split(X_fi, y_fi, test_size=0.25, random_state=42)\n",
        "train_X_h, test_x_h, train_y_h, test_y_h = train_test_split(X_h, y_h, test_size=0.25, random_state=42)\n",
        "train_X_dv, test_x_dv, train_y_dv, test_y_dv = train_test_split(X_dv, y_dv, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg1cik626noa"
      },
      "outputs": [],
      "source": [
        "train_data_fi = {'text': train_X_fi, 'labels': train_y_fi}\n",
        "test_data_fi = {'text': test_x_fi, 'labels': test_y_fi}\n",
        "\n",
        "df_train_data_fi = pd.DataFrame(train_data_fi)\n",
        "df_test_data_fi = pd.DataFrame(test_data_fi)\n",
        "\n",
        "df_train_data_fi = df_train_data_fi.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_test_data_fi = df_test_data_fi.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df_train_data_fi['labels'] = df_train_data_fi['labels'].replace(2, 0)\n",
        "df_test_data_fi['labels'] = df_test_data_fi['labels'].replace(2, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yqlnj6_p7Ehq"
      },
      "outputs": [],
      "source": [
        "train_data_h = {'text': train_X_h, 'labels': train_y_h}\n",
        "test_data_h = {'text': test_x_h, 'labels': test_y_h}\n",
        "\n",
        "df_train_data_h = pd.DataFrame(train_data_h)\n",
        "df_test_data_h = pd.DataFrame(test_data_h)\n",
        "\n",
        "df_train_data_h = df_train_data_h.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_test_data_h = df_test_data_h.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df_train_data_h['labels'] = df_train_data_h['labels'].replace(2, 0)\n",
        "df_test_data_h['labels'] = df_test_data_h['labels'].replace(2, 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dv = {'text': train_X_dv, 'labels': train_y_dv}\n",
        "test_data_dv = {'text': test_x_dv, 'labels': test_y_dv}\n",
        "\n",
        "df_train_data_dv = pd.DataFrame(train_data_dv)\n",
        "df_test_data_dv = pd.DataFrame(test_data_dv)\n",
        "\n",
        "df_train_data_dv = df_train_data_dv.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_test_data_dv = df_test_data_dv.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df_train_data_dv['labels'] = df_train_data_dv['labels'].replace(2, 0)\n",
        "df_test_data_dv['labels'] = df_test_data_dv['labels'].replace(2, 0)"
      ],
      "metadata": {
        "id": "NxcTvc5OO_Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5Wv0oA2QK5c"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9L6o2GCAQp1b"
      },
      "outputs": [],
      "source": [
        "def calculate_values(result, model):\n",
        "\n",
        "  # Calculate Precision\n",
        "  precision = result['tp'] / (result['tp'] + result['fp'])\n",
        "\n",
        "  # Calculate Recall (Sensitivity)\n",
        "  recall = result['tp'] / (result['tp'] + result['fn'])\n",
        "\n",
        "  # Calculate F1 Score\n",
        "  f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = (result['tp'] + result['tn']) / (result['tp'] + result['tn'] + result['fp'] + result['fn'])\n",
        "\n",
        "  # Calculate Specificity\n",
        "  specificity = result['tn'] / (result['tn'] + result['fp'])\n",
        "\n",
        "  # Calculate AUC-ROC\n",
        "  auc_roc = result['auroc']\n",
        "\n",
        "  # Calculate ROC\n",
        "  roc = {\n",
        "      'fpr': result['fp'] / (result['fp'] + result['tn']),\n",
        "      'tpr': recall\n",
        "  }\n",
        "\n",
        "  # Print the calculated metrics\n",
        "  print(\"Precision:\",model, \": \", precision)\n",
        "  print(\"Recall:\",model, \": \", recall)\n",
        "  print(\"F1 Score:\", model, \": \", f1)\n",
        "  print(\"Accuracy:\", model, \": \", accuracy)\n",
        "  print(\"Sensitivity:\", model, \": \", recall)\n",
        "  print(\"Specificity:\", model, \": \", specificity)\n",
        "  print(\"AUC-ROC:\", model, \": \", auc_roc)\n",
        "  print(\"ROC:\", model, \": \", roc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBMePD_Q8TGj"
      },
      "outputs": [],
      "source": [
        "def draw_plots(predicted_probabilities, true_labels, model):\n",
        "\n",
        "  auc_score = roc_auc_score(true_labels, predicted_probabilities)\n",
        "  fpr, tpr, _ = roc_curve(true_labels, predicted_probabilities)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(fpr, tpr, label=f\"auroc = {auc_score:.2f}\")\n",
        "  plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line representing random classification\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('Rceiver Operating Characteristic Curve for ' + model)\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.show()\n",
        "\n",
        "  print(\" \")\n",
        "\n",
        "  average_precision = average_precision_score(true_labels, predicted_probabilities)\n",
        "  precision, recall, _ = precision_recall_curve(true_labels, predicted_probabilities)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(recall, precision, label=f\"auprc = {average_precision:.2f}\")\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.title('Precision-Recall Curve for ' + model)\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjOJ-u-H8wkj"
      },
      "source": [
        "### Bert-Base-Uncased: Food Insecurity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mp2XJJHXD2w"
      },
      "outputs": [],
      "source": [
        "df_train_data_fi.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRswDXjN8UpW"
      },
      "outputs": [],
      "source": [
        "model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir = True, max_seq_length=512)\n",
        "\n",
        "model_bert_base_uncased = ClassificationModel(\n",
        "    \"bert\", \"bert-base-uncased\", args=model_args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(\"Epoch: \", i)\n",
        "  model_bert_base_uncased.train_model(df_train_data_fi)"
      ],
      "metadata": {
        "id": "jRyUFsQJW-4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP504ZDT8fPK"
      },
      "outputs": [],
      "source": [
        "result, model_outputs, wrong_predictions = model_bert_base_uncased.eval_model(df_test_data_fi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOjS4iHZw8q0"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3NZTVXXw-Bj"
      },
      "outputs": [],
      "source": [
        "calculate_values(result, 'bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeyX2aEf8qi1"
      },
      "outputs": [],
      "source": [
        "predicted_probabilities_bert_i2b2_fi = model_outputs[:, 1]\n",
        "true_labels_bert_i2b2_fi = np.array(df_test_data_fi['labels'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "draw_plots(predicted_probabilities_bert_i2b2_fi, true_labels_bert_i2b2_fi, 'bert-base-uncased')"
      ],
      "metadata": {
        "id": "Uz94U3TBv1zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToO_RXBCbAqQ"
      },
      "source": [
        "### Roberta: Food Insecurity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u31oeNzibIKs"
      },
      "outputs": [],
      "source": [
        "model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir = True, max_seq_length=512)\n",
        "\n",
        "model_roberta = ClassificationModel(\n",
        "    \"roberta\", \"roberta-base\", args=model_args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print('Epoch: ', i)\n",
        "  model_roberta.train_model(df_train_data_fi)"
      ],
      "metadata": {
        "id": "rtcEsp8XYyV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8MIBVoUbIKs"
      },
      "outputs": [],
      "source": [
        "result, model_outputs, wrong_predictions = model_roberta.eval_model(df_test_data_fi)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "VZQx325463-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_values(result, 'roberta-base')"
      ],
      "metadata": {
        "id": "X_zwkpaf63zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLSX8RdubIKt"
      },
      "outputs": [],
      "source": [
        "predicted_probabilities_roberta_i2b2_fi = model_outputs[:, 1]\n",
        "true_labels_roberta_i2b2_fi = np.array(df_test_data_fi['labels'].tolist())\n",
        "draw_plots(predicted_probabilities_roberta_i2b2_fi, true_labels_roberta_i2b2_fi, 'roberta-base')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4fbRz2zJlNC"
      },
      "source": [
        "### Bert-Base-Uncased: Homelessness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zr09iIAAbcvz"
      },
      "outputs": [],
      "source": [
        "model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir = True, max_seq_length=512)\n",
        "\n",
        "model_bert_base_uncased = ClassificationModel(\n",
        "    \"bert\", \"bert-base-uncased\", args=model_args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print('Epoch: ', i)\n",
        "  model_bert_base_uncased.train_model(df_train_data_h)"
      ],
      "metadata": {
        "id": "YhEj5zhngcVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result, model_outputs, wrong_predictions = model_bert_base_uncased.eval_model(df_test_data_h)"
      ],
      "metadata": {
        "id": "M0ighRUPgcNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "v3VT_kSo-2YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_values(result, 'bert-base-uncased')"
      ],
      "metadata": {
        "id": "RCHp0Hcf-2U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hc-9hY3HJwH_"
      },
      "outputs": [],
      "source": [
        "predicted_probabilities_bert_i2b2_h = model_outputs[:, 1]\n",
        "true_labels_bert_i2b2_h = np.array(df_test_data_h['labels'].tolist())\n",
        "draw_plots(predicted_probabilities_bert_i2b2_h, true_labels_bert_i2b2_h, 'bert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3oDIsJnJy06"
      },
      "source": [
        "### Roberta: Homelessness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F18jqlKcJwFm"
      },
      "outputs": [],
      "source": [
        "model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir = True, max_seq_length=512)\n",
        "\n",
        "model_roberta = ClassificationModel(\n",
        "    \"roberta\", \"roberta-base\", args=model_args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print('Epoch: ', i)\n",
        "  model_roberta.train_model(df_train_data_h)"
      ],
      "metadata": {
        "id": "IDm5G2QVih1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result, model_outputs, wrong_predictions = model_roberta.eval_model(df_test_data_h)"
      ],
      "metadata": {
        "id": "Lr2wDiqfijhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "pvWHk7jODNqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_values(result, 'roberta-base')"
      ],
      "metadata": {
        "id": "jF9eVWL-DNoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvMUljRpJ75V"
      },
      "outputs": [],
      "source": [
        "predicted_probabilities_roberta_i2b2_h = model_outputs[:, 1]\n",
        "true_labels_roberta_i2b2_h = np.array(df_test_data_h['labels'].tolist())\n",
        "draw_plots(predicted_probabilities_roberta_i2b2_h, true_labels_roberta_i2b2_h, 'roberta-base')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT: Domestic Violence"
      ],
      "metadata": {
        "id": "AWIHzEhGPcW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir = True, max_seq_length=512)\n",
        "\n",
        "model_bert_base_uncased = ClassificationModel(\n",
        "    \"bert\", \"bert-base-uncased\", args=model_args)"
      ],
      "metadata": {
        "id": "JYpRGRtKPhFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print('Epoch: ', i)\n",
        "  model_bert_base_uncased.train_model(df_train_data_dv)"
      ],
      "metadata": {
        "id": "G-kTnSYvPhCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result, model_outputs, wrong_predictions = model_bert_base_uncased.eval_model(df_test_data_dv)"
      ],
      "metadata": {
        "id": "JyvPg8p4Pt_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "qDd3vkdLGyT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_values(result, 'bert-base-uncased')"
      ],
      "metadata": {
        "id": "UvHxXokCj9QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities_bert_i2b2_dv = model_outputs[:, 1]\n",
        "true_labels_bert_i2b2_dv = np.array(df_test_data_dv['labels'].tolist())\n",
        "draw_plots(predicted_probabilities_bert_i2b2_dv, true_labels_bert_i2b2_dv, 'bert-base-uncased')"
      ],
      "metadata": {
        "id": "T9ALKwDnPg_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Roberta: Domestic Violence"
      ],
      "metadata": {
        "id": "_gQDUCRrPhce"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e3NmptXP2jo"
      },
      "outputs": [],
      "source": [
        "model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir = True, max_seq_length=512)\n",
        "\n",
        "model_roberta = ClassificationModel(\n",
        "    \"roberta\", \"roberta-base\", args=model_args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print('Epoch: ', i)\n",
        "  model_roberta.train_model(df_train_data_dv)"
      ],
      "metadata": {
        "id": "Sz6ad0iWP2jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result, model_outputs, wrong_predictions = model_roberta.eval_model(df_test_data_dv)"
      ],
      "metadata": {
        "id": "qT30MsonP2jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "MDnykiQnKo5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_values(result, 'roberta-base')"
      ],
      "metadata": {
        "id": "PlMz-tNyL4Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPXpXzEaP2jp"
      },
      "outputs": [],
      "source": [
        "predicted_probabilities_roberta_i2b2_dv = model_outputs[:, 1]\n",
        "true_labels_roberta_i2b2_dv = np.array(df_test_data_dv['labels'].tolist())\n",
        "draw_plots(predicted_probabilities_roberta_i2b2_dv, true_labels_roberta_i2b2_dv, 'roberta-base')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Y5Wv0oA2QK5c",
        "WjOJ-u-H8wkj",
        "ToO_RXBCbAqQ",
        "n4fbRz2zJlNC",
        "s3oDIsJnJy06",
        "AWIHzEhGPcW8",
        "_gQDUCRrPhce"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}